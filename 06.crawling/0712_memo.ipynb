{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "productive-driver",
   "metadata": {},
   "source": [
    "## 크롤링 기초다루기 \n",
    "### 웹 크롤링이란?\n",
    "#### 0712 memo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-accommodation",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-flash",
   "metadata": {},
   "source": [
    "### 데이터의 종류\n",
    "\n",
    "- 정형 데이터 - 숫자, 표로 정리할 수 있는 데이터 \n",
    "- 비 정형 데이터 - 문자, 표 형태가 아닌 데이터 \n",
    "\n",
    "> 데이터 분석에서 `데이터 수집`은 가장 중요한 능력 중 하나이다.  \n",
    "또한 뽑아낸 데이터들에서 EDA를 통해서 숨어있는 인사이트를 뽑아내는 것이 중요하다. \n",
    "\n",
    "> 쿠팡은 크롤링을 테스트하기 매우 좋은 사이트이다. \n",
    "\n",
    "> 네이버, 뉴스 등 크롤링을 막아둔 사이트가 요즘 많다. (자동입력방지 등 ,,,)  \n",
    "\n",
    "> 반응형 웹페이지 같은 경우 최대화 코드를 사용하여 초기화면을 만들어야한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-prior",
   "metadata": {},
   "source": [
    "### 크롤링 모듈\n",
    "\n",
    "- selenium은 특정요소만을 가지고 오는게 아니라 HTML문서 전체 다 가지고 온다.\n",
    "- beautiful soup는 selenium을 통해 가지고온 문서에서 원하는 부분만 골라서 저장하는 역할을 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-mercury",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-coral",
   "metadata": {},
   "source": [
    "## Selenium 간단한 사용법\n",
    "\n",
    "- '웹 페이지의 데이터를 가져온다'는 것은 '웹 페이지의 HTML 태그를 가져온다'라는 것과 같다.  \n",
    "- selenium은 html 태그를 코드를 통해 자동적으로 가지고 오는것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-memorial",
   "metadata": {},
   "source": [
    "### `-`실습문제 \n",
    "#### 경남대 홈페이지에서 오른쪽 상단 검색을 클릭하고 \"장학금\" 검색하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "purple-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "경남대 홈페이지에서 장학생 검색하기\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요 :  장학생\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"경남대 홈페이지에서 장학생 검색하기\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "query_txt = input(\"검색어를 입력하세요 : \")\n",
    "print(\"\\n\")\n",
    "\n",
    "chrome_path = \"C:/data/chromedriver.exe\" # 크롬 드라이브 실행 \n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "url = \"https://www.kyungnam.ac.kr/sites/ko/index.do\"\n",
    "driver.get(url) \n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[1]/div/div[3]/ul/li[1]/a').click() #검색 누르기 \n",
    "\n",
    "element = driver.find_element_by_id('top-search')\n",
    "driver.find_element_by_id('top-search').click()\n",
    "\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-government",
   "metadata": {},
   "source": [
    "### beautiful Soup 사용법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-plane",
   "metadata": {},
   "source": [
    "- bs4에서는 find(), find_all(), select() 함수를 사용한다. 사용자가 원하는 특정 태그를 가지고 올 수 있다.  \n",
    "\n",
    "- 전체 데이터에서 가지고 오고 싶은 태그 - 속성이 중복값이면 find 경로를 세세하게 다 구해야한다. (더 상위 클래스 태그를 설정해줘야함)\n",
    "\n",
    "- 셀리니엄의 파싱을 통해서 결국 특정 구간의 문서들만 전체 긁어오는것이니 제일 상위의 태그를 쓸 필요는 없다. \n",
    "\n",
    "- find('')에서 유일한 태그 - 속성을 쓰다면 따로 경로 추천을 하지 않아도 됨. / 여러개가 있다면 맨 처음 경로를 전해준다. \n",
    "\n",
    "- find_all() 해당 태그 밑에 모든 값들을 불러온다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-guinea",
   "metadata": {},
   "source": [
    "`Tip` HTML 코드 구조 \n",
    "\n",
    " HTML 코드 구조는 회사 조직도와 비슷하게 계층으로 이루어져 있다. \n",
    " \n",
    " ex)  < div class = 'title'>  => <태그 `속성 = \"속성값\"`>\n",
    " \n",
    " 위 태그를 검색하려면 find('태그명', '속성값')\n",
    " \n",
    " 속성값이 여러개이나 class로 구분될 경우 find('div', {class = 'title'} 으로 써도 된다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "상위 태그를 가지고 오면 자동으로 하위 태그는 다 가지고 온다. \n",
    "\n",
    "find('영업부').find('영업1팀').find('홍길동')\n",
    "\n",
    "동급이면 들여쓰기가 같다. (즉 위치가 비슷하다는것)\n",
    "\n",
    "<a href = 'dfdfdf'>\n",
    "\n",
    "a가 태그명 'dfdfdf'가 속성값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 사장실 조직도 \n",
    "<같은 동급에 태그가 같다면 상위 태그를 불러와야함 (상위 태그는 ,,, 들여쓰기를 잘봐야함)\n",
    "\n",
    "find('p','title)').find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "find함수에서는 가장 먼저 찾은 데이터를 가지고 온다. \n",
    "\n",
    "핫 스트링 = 셀리니엄으로 얻은 소스코드를 공부 시키는 것 \n",
    "\n",
    "원래 html 코드를 가져다 주는 것 \n",
    "soup = BeautifulSoup(ex1, 'html.parser')\n",
    "soup.find('title')\n",
    "\n",
    "\n",
    "soup.find('div','name').get_text() #저 태그 안에 있는 내용(문자)만 가지고 온다. \n",
    "\n",
    "데이터 많으면 ,, for문을 돌려서 가지공 오거라 ,, 허허허헣\n",
    "\n",
    "속성값이 여러개 있는지 확인하는 방법은 \n",
    "속성값을 더블클릭한 뒤 \n",
    "컨 + F 한 뒤에 \n",
    "거기에 검색 넣으면 match에 몇개 나오는지 알 수 있다~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "추가해야할 내용 첨부"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
